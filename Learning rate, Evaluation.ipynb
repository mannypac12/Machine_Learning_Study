{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Training Data\n",
    "x_train = [[1,2,1], [1,3,2], [1,3,4], [1,5,5], [1,7,5], [1,2,5], [1,6,6], [1,7,7]]\n",
    "y_train = [[0,0,1], [0,0,1], [0,0,1], [0,1,0], [0,1,0], [0,1,0], [1,0,6], [1,0,0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Evaluation Model\n",
    "\n",
    "x_test = [[2,1,1], [3,1,2], [3,3,4]]\n",
    "y_test = [[0,0,1], [0,0,1], [0,0,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2, 1, 1], [3, 1, 2], [3, 3, 4]]\n",
      "[[0, 0, 1], [0, 0, 1], [0, 0, 1]]\n"
     ]
    }
   ],
   "source": [
    "print(x_test)\n",
    "print(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Assign Variables \n",
    "\n",
    "X = tf.placeholder(\"float\", [None, 3])\n",
    "Y = tf.placeholder(\"float\", [None, 3])\n",
    "W = tf.Variable(tf.random_normal([3,3]))\n",
    "b = tf.Variable(tf.random_normal([3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "hypothesis = tf.nn.softmax(tf.matmul(X, W)+b)\n",
    "cost = tf.reduce_mean(-tf.reduce_sum(Y * tf.log(hypothesis), axis = 1))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.1).minimize(cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Correnct Prediction Test Model\n",
    "\n",
    "prediction = tf.argmax(hypothesis, 1)\n",
    "is_correct = tf.equal(prediction, tf.arg_max(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(is_correct, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 5.670203 [[ 0.92011034  1.4769454   1.7483612 ]\n",
      " [ 0.7019692   1.2674932   1.5170476 ]\n",
      " [-2.044698   -0.08969346 -0.81451076]]\n",
      "1 5.6266756 [[ 0.9436215   1.3756992   1.8260963 ]\n",
      " [ 0.8613281   0.7069414   1.9182405 ]\n",
      " [-1.8838676  -0.6535692  -0.41146535]]\n",
      "2 6.891539 [[ 0.96763945  1.412762    1.7650155 ]\n",
      " [ 1.0217813   0.8809436   1.5837852 ]\n",
      " [-1.7224516  -0.46710104 -0.7593496 ]]\n",
      "3 3.4065466 [[ 0.98797816  1.4399254   1.7175134 ]\n",
      " [ 1.1736224   1.0188208   1.2940669 ]\n",
      " [-1.5666009  -0.32647642 -1.0558248 ]]\n",
      "4 3.3197155 [[ 0.9985966   1.347685    1.7991354 ]\n",
      " [ 1.2941852   0.49461138  1.6977136 ]\n",
      " [-1.4356209  -0.8578861  -0.65539515]]\n",
      "5 4.6677475 [[ 1.0151092   1.384801    1.7455068 ]\n",
      " [ 1.4354199   0.66871107  1.3823792 ]\n",
      " [-1.2887208  -0.671464   -0.98871726]]\n",
      "6 2.5018258 [[ 0.95173377  1.4167274   1.7769557 ]\n",
      " [ 1.1658843   0.8235204   1.4971055 ]\n",
      " [-1.5483886  -0.5107331  -0.88978034]]\n",
      "7 2.4811354 [[ 0.96618265  1.439127    1.7401073 ]\n",
      " [ 1.2992542   0.9386863   1.2485697 ]\n",
      " [-1.4087648  -0.39665833 -1.1434789 ]]\n",
      "8 2.8511324 [[ 0.95213115  1.3678693   1.8254164 ]\n",
      " [ 1.2951889   0.5263324   1.6649889 ]\n",
      " [-1.3959284  -0.81948185 -0.73349184]]\n",
      "9 4.1496553 [[ 0.96726537  1.4047571   1.7733943 ]\n",
      " [ 1.4313515   0.6998515   1.3553071 ]\n",
      " [-1.25448    -0.63394773 -1.0604743 ]]\n",
      "10 2.5521383 [[ 0.88500273  1.4335746   1.8268396 ]\n",
      " [ 1.0511261   0.8409135   1.5944705 ]\n",
      " [-1.6240274  -0.4895844  -0.8352903 ]]\n",
      "11 3.183293 [[ 0.9051618   1.4610107   1.7792444 ]\n",
      " [ 1.2021362   0.98041683  1.3039571 ]\n",
      " [-1.4693099  -0.3481136  -1.1314785 ]]\n",
      "12 3.0721598 [[ 0.912283    1.372803    1.8603309 ]\n",
      " [ 1.3046108   0.47763622  1.7042631 ]\n",
      " [-1.3560483  -0.85950404 -0.73334956]]\n",
      "13 4.4071627 [[ 0.92833996  1.4098767   1.8072002 ]\n",
      " [ 1.4432917   0.65163565  1.391583  ]\n",
      " [-1.2128348  -0.6732828  -1.0627843 ]]\n",
      "14 2.7037861 [[ 0.8456755   1.4420577   1.8576835 ]\n",
      " [ 1.0615128   0.8078809   1.6171165 ]\n",
      " [-1.5867975  -0.51103204 -0.85107243]]\n",
      "15 3.2496176 [[ 0.8660703  1.4715699  1.8077766]\n",
      " [ 1.2129874  0.9563174  1.3172052]\n",
      " [-1.4319836 -0.3592909 -1.1576275]]\n",
      "16 2.875591 [[ 0.8711725   1.3884987   1.8857455 ]\n",
      " [ 1.3039892   0.48232493  1.7001959 ]\n",
      " [-1.3301569  -0.8430412  -0.7757039 ]]\n",
      "17 4.20914 [[ 0.8868965  1.4254869  1.8330332]\n",
      " [ 1.4409219  0.6561141  1.389474 ]\n",
      " [-1.1892947 -0.657165  -1.1024423]]\n",
      "18 2.743216 [[ 0.797577    1.4568117   1.8910279 ]\n",
      " [ 1.019103    0.8089839   1.658423  ]\n",
      " [-1.603564   -0.49920365 -0.8461342 ]]\n",
      "19 3.5070956 [[ 0.8192671   1.4871709   1.8389785 ]\n",
      " [ 1.1739058   0.9611252   1.3514788 ]\n",
      " [-1.4462467  -0.34321675 -1.1594385 ]]\n",
      "20 2.8982477 [[ 0.8296319   1.4031886   1.9125961 ]\n",
      " [ 1.287841    0.48462987  1.714039  ]\n",
      " [-1.3236506  -0.82989556 -0.7953559 ]]\n",
      "21 4.2038503 [[ 0.84642285  1.4401354   1.8588583 ]\n",
      " [ 1.4279009   0.6583222   1.4002867 ]\n",
      " [-1.1802564  -0.6441853  -1.1244605 ]]\n",
      "22 2.6204507 [[ 0.76133716  1.4704942   1.9135853 ]\n",
      " [ 1.0271567   0.8072829   1.6520702 ]\n",
      " [-1.5739815  -0.49108768 -0.8838329 ]]\n",
      "23 3.33292 [[ 0.7829578   1.4995108   1.8629481 ]\n",
      " [ 1.1816536   0.9542949   1.3505613 ]\n",
      " [-1.4170712  -0.34187853 -1.1899524 ]]\n",
      "24 2.9372602 [[ 0.79265076  1.4134933   1.9392726 ]\n",
      " [ 1.2914759   0.46630958  1.7287242 ]\n",
      " [-1.2985889  -0.83999836 -0.81031483]]\n",
      "25 4.243972 [[ 0.8097899   1.4504837   1.885143  ]\n",
      " [ 1.4322368   0.64011544  1.4141575 ]\n",
      " [-1.1550097  -0.6541363  -1.1397561 ]]\n",
      "26 2.6856234 [[ 0.7229271  1.4817191  1.9407704]\n",
      " [ 1.0203352  0.793075   1.6730996]\n",
      " [-1.5611697 -0.4963396 -0.8913927]]\n",
      "27 3.4311428 [[ 0.74497527  1.5116757   1.8887657 ]\n",
      " [ 1.1758689   0.9440185   1.3666224 ]\n",
      " [-1.403568   -0.3425445  -1.2027894 ]]\n",
      "28 2.8528538 [[ 0.75548875  1.4278591   1.9620689 ]\n",
      " [ 1.2880235   0.46917427  1.729312  ]\n",
      " [-1.2834533  -0.8282592  -0.8371893 ]]\n",
      "29 4.1406364 [[ 0.77275485  1.4647849   1.9078771 ]\n",
      " [ 1.4287355   0.6428233   1.4149508 ]\n",
      " [-1.1403955  -0.6426654  -1.1658411 ]]\n",
      "30 2.6744676 [[ 0.68399537  1.4952515   1.96617   ]\n",
      " [ 1.0035925   0.792763    1.6901542 ]\n",
      " [-1.5599283  -0.48869288 -0.9002809 ]]\n",
      "31 3.5044842 [[ 0.7065029   1.5252304   1.9136835 ]\n",
      " [ 1.1602511   0.94398624  1.3822722 ]\n",
      " [-1.4015222  -0.33483312 -1.2125467 ]]\n",
      "32 2.8805532 [[ 0.71904093  1.440725    1.985651  ]\n",
      " [ 1.2804873   0.4663945   1.7396278 ]\n",
      " [-1.2742832  -0.82358587 -0.85103285]]\n",
      "33 4.15026 [[ 0.73698443  1.4776369   1.9307956 ]\n",
      " [ 1.423134    0.6400144   1.4233613 ]\n",
      " [-1.129672   -0.6380564  -1.1811736 ]]\n",
      "34 2.6131506 [[ 0.6506164   1.5077001   1.9871004 ]\n",
      " [ 1.009103    0.78845835  1.6889484 ]\n",
      " [-1.5386497  -0.48603243 -0.9242198 ]]\n",
      "35 3.4159896 [[ 0.6731611   1.5370747   1.935181  ]\n",
      " [ 1.1657785   0.93747216  1.383259  ]\n",
      " [-1.3803421  -0.33525163 -1.2333082 ]]\n",
      "36 2.883356 [[ 0.68544686  1.4517642   2.0082057 ]\n",
      " [ 1.2839222   0.45542803  1.7471596 ]\n",
      " [-1.2553273  -0.82852364 -0.86505103]]\n",
      "37 4.1524763 [[ 0.7035842   1.4886931   1.9531394 ]\n",
      " [ 1.4268405   0.62909347  1.4305758 ]\n",
      " [-1.1108179  -0.64294124 -1.1951429 ]]\n",
      "38 2.6573844 [[ 0.61559683  1.5191903   2.0106297 ]\n",
      " [ 1.0022154   0.7796071   1.7046875 ]\n",
      " [-1.5311638  -0.48853517 -0.92920303]]\n",
      "39 3.4986575 [[ 0.6384433   1.5491719   1.9578016 ]\n",
      " [ 1.159625    0.93111086  1.395774  ]\n",
      " [-1.3723434  -0.3348139  -1.2417446 ]]\n",
      "40 2.8350322 [[ 0.651675    1.465325    2.0284169 ]\n",
      " [ 1.2809843   0.4579591   1.7475667 ]\n",
      " [-1.244734   -0.81976414 -0.8844037 ]]\n",
      "41 4.0827622 [[ 0.6700088  1.5021994  1.9732087]\n",
      " [ 1.4242026  0.6314931  1.4308144]\n",
      " [-1.1002548 -0.6344116 -1.2142354]]\n",
      "42 2.6344314 [[ 0.5815242   1.5319912   2.0319016 ]\n",
      " [ 0.99428785  0.77924573  1.7129763 ]\n",
      " [-1.525908   -0.48349944 -0.9394944 ]]\n",
      "43 3.5195773 [[ 0.6045994   1.5618119   1.9790057 ]\n",
      " [ 1.1522421   0.9302607   1.4040071 ]\n",
      " [-1.3667104  -0.33062157 -1.2515697 ]]\n",
      "44 2.8601534 [[ 0.6189229   1.4772643   2.0492299 ]\n",
      " [ 1.2776947   0.45376977  1.7550454 ]\n",
      " [-1.2355645  -0.81906664 -0.89427066]]\n",
      "45 4.0977573 [[ 0.6377304   1.5141383   1.9935483 ]\n",
      " [ 1.42225     0.62730664  1.4369531 ]\n",
      " [-1.089996   -0.63372487 -1.225181  ]]\n",
      "46 2.5999286 [[ 0.55081487  1.5437782   2.0508242 ]\n",
      " [ 0.99910325  0.77462167  1.7127848 ]\n",
      " [-1.509376   -0.4834711  -0.9560547 ]]\n",
      "47 3.4675894 [[ 0.57394147  1.573301    1.9981748 ]\n",
      " [ 1.1571368   0.9245902   1.4047827 ]\n",
      " [-1.3501909  -0.3321314  -1.2665795 ]]\n",
      "48 2.8503847 [[ 0.5881644   1.4884535   2.0687993 ]\n",
      " [ 1.281331    0.44650578  1.758673  ]\n",
      " [-1.2204522  -0.82226574 -0.9061837 ]]\n",
      "49 4.0863523 [[ 0.60708815  1.5253327   2.0129962 ]\n",
      " [ 1.4259615   0.6200581   1.4404901 ]\n",
      " [-1.0750804  -0.6369142  -1.236907  ]]\n",
      "50 2.63393 [[ 0.5187904   1.5552088   2.0714178 ]\n",
      " [ 0.99348927  0.76858467  1.7244358 ]\n",
      " [-1.5042658  -0.48530877 -0.959327  ]]\n",
      "51 3.5359604 [[ 0.54212755  1.5851722   2.0181174 ]\n",
      " [ 1.1520368   0.92032915  1.4141438 ]\n",
      " [-1.3447093  -0.33183908 -1.2723532 ]]\n",
      "52 2.820228 [[ 0.5571795   1.5014043   2.0868332 ]\n",
      " [ 1.2791636   0.44883093  1.7585151 ]\n",
      " [-1.2125341  -0.8158313  -0.9205363 ]]\n",
      "53 4.036449 [[ 0.57630676  1.5382376   2.0308728 ]\n",
      " [ 1.4242036   0.6222728   1.4400332 ]\n",
      " [-1.066974   -0.6306752  -1.2512524 ]]\n",
      "54 2.607079 [[ 0.48816568  1.567476    2.0897753 ]\n",
      " [ 0.9902625   0.7683158   1.7279314 ]\n",
      " [-1.4975783  -0.48221523 -0.9691081 ]]\n",
      "55 3.5329084 [[ 0.5116305   1.5972207   2.0365658 ]\n",
      " [ 1.1491054   0.919315    1.4180893 ]\n",
      " [-1.3378246  -0.32986534 -1.2812116 ]]\n",
      "56 2.8415248 [[ 0.52732223  1.5127497   2.105345  ]\n",
      " [ 1.2784739   0.4442059   1.76383   ]\n",
      " [-1.2037563  -0.81752527 -0.92762005]]\n",
      "57 4.0532475 [[ 0.5467922   1.5495908   2.0490339 ]\n",
      " [ 1.4244695   0.6176701   1.4443702 ]\n",
      " [-1.0574037  -0.63234425 -1.2591538 ]]\n",
      "58 2.588654 [[ 0.4596926   1.5788282   2.1068962 ]\n",
      " [ 0.9945853   0.76389945  1.7280251 ]\n",
      " [-1.4843773  -0.48377484 -0.9807496 ]]\n",
      "59 3.5028186 [[ 0.48320785  1.6084485   2.0537605 ]\n",
      " [ 1.1535212   0.9144908   1.4184978 ]\n",
      " [-1.3246008  -0.33208573 -1.2922152 ]]\n",
      "60 2.8261857 [[ 0.49887836  1.523965    2.1225736 ]\n",
      " [ 1.2821193   0.4394117   1.7649788 ]\n",
      " [-1.1914458  -0.8198215  -0.93763447]]\n",
      "61 4.0352206 [[ 0.51842284  1.5608038   2.0661902 ]\n",
      " [ 1.4280969   0.61287194  1.445541  ]\n",
      " [-1.0453098  -0.6346583  -1.2689337 ]]\n",
      "62 2.6148949 [[ 0.43018788  1.5901448   2.1250842 ]\n",
      " [ 0.9902869   0.7597378   1.7364851 ]\n",
      " [-1.4804859  -0.48542678 -0.98298895]]\n",
      "63 3.5581057 [[ 0.45385277  1.6200899   2.071474  ]\n",
      " [ 1.1495894   0.9116195   1.4253008 ]\n",
      " [-1.3204368  -0.3321675  -1.2962973 ]]\n",
      "64 2.807617 [[ 0.47021213  1.5363955   2.138809  ]\n",
      " [ 1.280682    0.4413727   1.7644552 ]\n",
      " [-1.1851742  -0.81540555 -0.9483218 ]]\n",
      "65 3.9999266 [[ 0.48995206  1.5731972   2.0822673 ]\n",
      " [ 1.4271079   0.6147437   1.4446582 ]\n",
      " [-1.0387329  -0.630401   -1.2797678 ]]\n",
      "66 2.587554 [[ 0.4022162   1.6019834   2.141217  ]\n",
      " [ 0.9899396   0.7594671   1.737103  ]\n",
      " [-1.4731894  -0.48389047 -0.9918219 ]]\n",
      "67 3.5428045 [[ 0.42595702  1.631702    2.0877576 ]\n",
      " [ 1.1494118   0.91054964  1.4265482 ]\n",
      " [-1.3130332  -0.3317797  -1.3040887 ]]\n",
      "68 2.824371 [[ 0.4426958   1.5473385   2.1553824 ]\n",
      " [ 1.281703    0.43674502  1.7680616 ]\n",
      " [-1.1767973  -0.8185673  -0.9535372 ]]\n",
      "69 4.015917 [[ 0.46268514  1.5841527   2.0985787 ]\n",
      " [ 1.4288077   0.61014897  1.4475529 ]\n",
      " [-1.0297867  -0.6335162  -1.2855989 ]]\n",
      "70 2.5801923 [[ 0.37558842  1.6130302   2.156798  ]\n",
      " [ 0.9936618   0.7554328   1.737415  ]\n",
      " [-1.4625788  -0.48643023 -0.9998927 ]]\n",
      "71 3.5283523 [[ 0.39937675  1.6427362   2.1033037 ]\n",
      " [ 1.1532302   0.9065101   1.4267693 ]\n",
      " [-1.3023804  -0.33441275 -1.3121085 ]]\n",
      "72 2.8067758 [[ 0.41615146  1.558545    2.17072   ]\n",
      " [ 1.2851199   0.43378428  1.7676054 ]\n",
      " [-1.1666807  -0.82023215 -0.9619888 ]]\n",
      "73 3.9945343 [[ 0.4361952   1.5953512   2.1138701 ]\n",
      " [ 1.4321765   0.60716987  1.4471632 ]\n",
      " [-1.0198627  -0.63521963 -1.2938193 ]]\n",
      "74 2.5991833 [[ 0.3482221   1.6242256   2.1729689 ]\n",
      " [ 0.9905962   0.7526306   1.7432828 ]\n",
      " [-1.4592183  -0.48802269 -1.0016606 ]]\n",
      "75 3.5709977 [[ 0.37211803  1.6541607   2.1191378 ]\n",
      " [ 1.1504289   0.9046086   1.431472  ]\n",
      " [-1.298819   -0.33489728 -1.3151853 ]]\n",
      "76 2.7964244 [[ 0.38945016  1.5705047   2.1854618 ]\n",
      " [ 1.2843685   0.43519345  1.7669474 ]\n",
      " [-1.161367   -0.81764394 -0.9698906 ]]\n",
      "77 3.9709964 [[ 0.40967578  1.6072829   2.128458  ]\n",
      " [ 1.4318784   0.6085119   1.4461191 ]\n",
      " [-1.0141846  -0.6327511  -1.3019658 ]]\n",
      "78 2.573593 [[ 0.3223632   1.6357008   2.1873527 ]\n",
      " [ 0.99205697  0.7522352   1.7422173 ]\n",
      " [-1.4517051  -0.48777336 -1.009423  ]]\n",
      "79 3.5501971 [[ 0.3463069  1.6654291  2.1336808]\n",
      " [ 1.1519918  0.903472   1.4310457]\n",
      " [-1.2912467 -0.3356894 -1.3219655]]\n",
      "80 2.8082325 [[ 0.3638595   1.5811789   2.2003784 ]\n",
      " [ 1.2865012   0.43084845  1.7691599 ]\n",
      " [-1.1533748  -0.82159984 -0.9739269 ]]\n",
      "81 3.9841847 [[ 0.384265    1.6179712   2.1431806 ]\n",
      " [ 1.4344783   0.60420287  1.4478284 ]\n",
      " [-1.0058019  -0.6366519  -1.3064477 ]]\n",
      "82 2.573956 [[ 0.2972762   1.6465267   2.201614  ]\n",
      " [ 0.9950961   0.74866617  1.7427473 ]\n",
      " [-1.4431717  -0.4908688  -1.014861  ]]\n",
      "83 3.5473044 [[ 0.32126412  1.6763139   2.1478388 ]\n",
      " [ 1.1551263   0.90015066  1.4312326 ]\n",
      " [-1.2826595  -0.33851373 -1.3277283 ]]\n",
      "84 2.7904925 [[ 0.33889794  1.5923502   2.2141685 ]\n",
      " [ 1.2895348   0.4292584   1.7677164 ]\n",
      " [-1.1450154  -0.82280433 -0.98108184]]\n",
      "85 3.961687 [[ 0.35935092  1.6291304   2.1569355 ]\n",
      " [ 1.437473    0.602584    1.4464525 ]\n",
      " [-0.99758464 -0.6379098  -1.3134071 ]]\n",
      "86 2.5860367 [[ 0.2717479   1.6575965   2.2160723 ]\n",
      " [ 0.99317515  0.7468542   1.7464802 ]\n",
      " [-1.4398935  -0.49245918 -1.0165489 ]]\n",
      "87 3.577889 [[ 0.29581356  1.6875309   2.1620722 ]\n",
      " [ 1.1533962   0.8989139   1.4341993 ]\n",
      " [-1.279234   -0.33939224 -1.3302753 ]]\n",
      "88 2.7860098 [[ 0.3138878   1.6038789   2.22765   ]\n",
      " [ 1.2894353   0.43000594  1.7670684 ]\n",
      " [-1.140186   -0.8218529  -0.98686266]]\n",
      "89 3.9475935 [[ 0.33450562  1.6406399   2.1702712 ]\n",
      " [ 1.4378077   0.60328597  1.445416  ]\n",
      " [-0.9923738  -0.63703966 -1.319488  ]]\n",
      "90 2.5637875 [[ 0.24760205  1.6687559   2.2290587 ]\n",
      " [ 0.9957052   0.7462547   1.7445498 ]\n",
      " [-1.4324298  -0.4932686  -1.0232031 ]]\n",
      "91 3.5560899 [[ 0.2716999   1.6985195   2.1751974 ]\n",
      " [ 1.1559919   0.89769703  1.4328206 ]\n",
      " [-1.271736   -0.34105712 -1.3361084 ]]\n",
      "92 2.792904 [[ 0.28989834  1.6143806   2.2411377 ]\n",
      " [ 1.2922256   0.42614895  1.7681348 ]\n",
      " [-1.1325966  -0.8260993  -0.99020565]]\n",
      "93 3.9567602 [[ 0.3106442   1.6511546   2.1836178 ]\n",
      " [ 1.4409034   0.5994619   1.4461441 ]\n",
      " [-0.9845353  -0.64123327 -1.323133  ]]\n",
      "94 2.5691276 [[ 0.22383174  1.6794168   2.2421682 ]\n",
      " [ 0.99808085  0.74319434  1.7452343 ]\n",
      " [-1.4255297  -0.49661767 -1.0267541 ]]\n",
      "95 3.5612013 [[ 0.2479702   1.7092794   2.188167  ]\n",
      " [ 1.1584592   0.89502275  1.4330275 ]\n",
      " [-1.2647767  -0.34392846 -1.3401964 ]]\n",
      "96 2.776472 [[ 0.2662831  1.6254824  2.2536511]\n",
      " [ 1.2948264  0.4255239  1.7661592]\n",
      " [-1.1256219 -0.8270283 -0.9962513]]\n",
      "97 3.9349313 [[ 0.2870766   1.6622419   2.196098  ]\n",
      " [ 1.4434961   0.598802    1.4442114 ]\n",
      " [-0.9776406  -0.64222395 -1.3290368 ]]\n",
      "98 2.5750556 [[ 0.19989553  1.6903517   2.2551694 ]\n",
      " [ 0.99719405  0.7420712   1.7472442 ]\n",
      " [-1.4220669  -0.4982633  -1.0285711 ]]\n",
      "99 3.5809479 [[ 0.2240903   1.7202946   2.2010317 ]\n",
      " [ 1.15771     0.89421326  1.4345863 ]\n",
      " [-1.2612072  -0.345186   -1.3425081 ]]\n",
      "100 2.775885 [[ 0.2427427   1.636625    2.266049  ]\n",
      " [ 1.2953284   0.42561194  1.7655692 ]\n",
      " [-1.1209723  -0.82747376 -1.0004553 ]]\n",
      "101 3.9279883 [[ 0.2636817  1.6733733  2.2083616]\n",
      " [ 1.4443944  0.5988634  1.4432518]\n",
      " [-0.9726245 -0.6427166 -1.3335602]]\n",
      "102 2.5570736 [[ 0.17715703  1.7012358   2.2670238 ]\n",
      " [ 1.0002561   0.7412511   1.7450026 ]\n",
      " [-1.414854   -0.4999153  -1.0341319 ]]\n",
      "103 3.5610814 [[ 0.2013754   1.7310511   2.21299   ]\n",
      " [ 1.1608183   0.8929301   1.4327614 ]\n",
      " [-1.2539719  -0.34747297 -1.3474563 ]]\n",
      "104 2.7783632 [[ 0.22009692  1.6470176   2.278302  ]\n",
      " [ 1.2984266   0.42236757  1.7657156 ]\n",
      " [-1.1138227  -0.8316646  -1.0034139 ]]\n",
      "105 3.9327493 [[ 0.24112633  1.6837763   2.2205138 ]\n",
      " [ 1.447679    0.59564507  1.4431857 ]\n",
      " [-0.9653311  -0.6468643  -1.3367057 ]]\n",
      "106 2.5650573 [[ 0.15454037  1.711766    2.27911   ]\n",
      " [ 1.0020754   0.73870826  1.7457261 ]\n",
      " [-1.4091766  -0.5033171  -1.0364072 ]]\n",
      "107 3.5709574 [[ 0.17879523  1.741696    2.224925  ]\n",
      " [ 1.1627227   0.890823    1.4329641 ]\n",
      " [-1.2482345  -0.35031378 -1.3503526 ]]\n",
      "108 2.764141 [[ 0.19765148  1.6580104   2.2897544 ]\n",
      " [ 1.3006287   0.42234567  1.7635354 ]\n",
      " [-1.1078959  -0.8325161  -1.008489  ]]\n",
      "109 3.9129405 [[ 0.2187315   1.6947538   2.231931  ]\n",
      " [ 1.449911    0.59558636  1.4410123 ]\n",
      " [-0.9594225  -0.6477791  -1.3416994 ]]\n",
      "110 2.5660248 [[ 0.1319874   1.722554    2.2908747 ]\n",
      " [ 1.0020788   0.73802394  1.7464069 ]\n",
      " [-1.4054072  -0.5050785  -1.0384152 ]]\n",
      "111 3.5816925 [[ 0.1562832   1.7525136   2.2366192 ]\n",
      " [ 1.1628251   0.89025784  1.4334267 ]\n",
      " [-1.2443887  -0.35193017 -1.3525821 ]]\n",
      "112 2.7657518 [[ 0.17539477  1.6688182   2.301203  ]\n",
      " [ 1.3016531   0.42187145  1.7629851 ]\n",
      " [-1.103256   -0.83407426 -1.0115707 ]]\n",
      "113 3.9108868 [[ 0.19659978  1.7055568   2.2432594 ]\n",
      " [ 1.4512811   0.5951006   1.4401281 ]\n",
      " [-0.954453   -0.64935726 -1.3450906 ]]\n",
      "114 2.5525932 [[ 0.11042006  1.7331989   2.3017972 ]\n",
      " [ 1.0052872   0.7370188   1.7442038 ]\n",
      " [-1.398588   -0.50736606 -1.0429468 ]]\n",
      "115 3.5654202 [[ 0.13473481  1.7630744   2.247607  ]\n",
      " [ 1.1660703   0.8889465   1.431493  ]\n",
      " [-1.2375516  -0.35463303 -1.3567162 ]]\n",
      "116 2.7646508 [[ 0.15388772  1.6791371   2.3123913 ]\n",
      " [ 1.3047986   0.4192842   1.7624271 ]\n",
      " [-1.096578   -0.8380052  -1.0143175 ]]\n",
      "117 3.9115448 [[ 0.17515703  1.7158825   2.2543766 ]\n",
      " [ 1.4545313   0.59253067  1.4394479 ]\n",
      " [-0.94770336 -0.6532583  -1.347939  ]]\n",
      "118 2.561336 [[ 0.08883583  1.7436163   2.312964  ]\n",
      " [ 1.0067034   0.73496944  1.744837  ]\n",
      " [-1.3937616  -0.5107031  -1.044436  ]]\n",
      "119 3.5772839 [[ 0.11318265  1.773604    2.2586293 ]\n",
      " [ 1.167563    0.8873184   1.4316286 ]\n",
      " [-1.2326684  -0.35741603 -1.3588163 ]]\n",
      "120 2.7530494 [[ 0.132478    1.689983    2.3229551 ]\n",
      " [ 1.3066846   0.41956258  1.7602627 ]\n",
      " [-1.0913987  -0.83896124 -1.0185407 ]]\n",
      "121 3.894624 [[ 0.15380096  1.7267139   2.2649014 ]\n",
      " [ 1.4564826   0.5927739   1.4372534 ]\n",
      " [-0.9424892  -0.6542735  -1.3521379 ]]\n",
      "122 2.5587728 [[ 0.06748498  1.7542454   2.323686  ]\n",
      " [ 1.0074254   0.7345265   1.744558  ]\n",
      " [-1.3896683  -0.51263237 -1.0465999 ]]\n",
      "123 3.581164 [[ 0.09186187  1.784229    2.2693253 ]\n",
      " [ 1.1683564   0.88686526  1.4312881 ]\n",
      " [-1.2285206  -0.35936213 -1.3610178 ]]\n",
      "124 2.7554815 [[ 0.11134481  1.7005095   2.333562  ]\n",
      " [ 1.3081275   0.41867968  1.7597026 ]\n",
      " [-1.0866973  -0.8413327  -1.0208706 ]]\n",
      "125 3.895404 [[ 0.13277243  1.7372398   2.275404  ]\n",
      " [ 1.4582138   0.59189     1.436406  ]\n",
      " [-0.93750775 -0.6566458  -1.354747  ]]\n",
      "126 2.54964 [[ 0.0469075   1.7646825   2.3338263 ]\n",
      " [ 1.0105234   0.7334026   1.7425838 ]\n",
      " [-1.3833227  -0.51536536 -1.0502125 ]]\n",
      "127 3.5691133 [[ 0.07130074  1.7946204   2.2794952 ]\n",
      " [ 1.171487    0.8855747   1.4294481 ]\n",
      " [-1.2221581  -0.36231688 -1.3644257 ]]\n",
      "128 2.751802 [[ 0.09081442  1.7107666   2.3438354 ]\n",
      " [ 1.311143    0.41672266  1.7586442 ]\n",
      " [-1.0804999  -0.8449186  -1.0234821 ]]\n",
      "129 3.8927298 [[ 0.11228928  1.7475002   2.285627  ]\n",
      " [ 1.4612832   0.5899415   1.4352852 ]\n",
      " [-0.9312819  -0.6602157  -1.3574029 ]]\n",
      "130 2.5577838 [[ 0.02626037  1.7749925   2.3441634 ]\n",
      " [ 1.0116948   0.73179454  1.7430205 ]\n",
      " [-1.3790321  -0.5185852  -1.0512831 ]]\n",
      "131 3.58084 [[ 0.05068118  1.8050287   2.2897065 ]\n",
      " [ 1.1727248   0.88433325  1.4294517 ]\n",
      " [-1.217816   -0.36504698 -1.3660375 ]]\n",
      "132 2.7428224 [[ 0.07033451  1.7214358   2.353646  ]\n",
      " [ 1.3128103   0.41707346  1.756626  ]\n",
      " [-1.0758137  -0.8461163  -1.0269705 ]]\n",
      "133 3.8790555 [[ 0.0918646   1.7581567   2.2953951 ]\n",
      " [ 1.4630427   0.59026146  1.4332056 ]\n",
      " [-0.9265213  -0.66146415 -1.3609151 ]]\n",
      "134 2.553119 [[ 0.00595356  1.7854537   2.3540092 ]\n",
      " [ 1.0129495   0.73145     1.7421103 ]\n",
      " [-1.3746655  -0.5207149  -1.0535202 ]]\n",
      "135 3.5800424 [[ 0.03039685  1.8154668   2.2995527 ]\n",
      " [ 1.1740319   0.88390625  1.4285717 ]\n",
      " [-1.2134104  -0.3672831  -1.3682071 ]]\n",
      "136 2.7450767 [[ 0.05018541  1.7317306   2.3635004 ]\n",
      " [ 1.3145522   0.4159521   1.7560056 ]\n",
      " [-1.0710455  -0.84901905 -1.028836  ]]\n",
      "137 3.8809984 [[ 0.0718012  1.7684534  2.3051617]\n",
      " [ 1.4650152  0.589145   1.4323498]\n",
      " [-0.9215267 -0.6643565 -1.3630174]]\n",
      "138 2.547647 [[-0.01377196  1.795709    2.3634791 ]\n",
      " [ 1.0157899   0.7302829   1.7404373 ]\n",
      " [-1.3688109  -0.5237299  -1.0563599 ]]\n",
      "139 3.5720544 [[ 0.01068611  1.8257065   2.3090236 ]\n",
      " [ 1.1769025   0.882683    1.4269245 ]\n",
      " [-1.2075381  -0.37036723 -1.3709953 ]]\n",
      "140 2.7398105 [[ 0.03050444  1.7419208   2.3729908 ]\n",
      " [ 1.3173343   0.41454542  1.7546303 ]\n",
      " [-1.0653064  -0.85226285 -1.0313313 ]]\n",
      "141 3.8759744 [[ 0.05215704  1.7786438   2.3146152 ]\n",
      " [ 1.4678239   0.58773935  1.430947  ]\n",
      " [-0.9157803  -0.6675963  -1.3655239 ]]\n",
      "142 2.5543811 [[-0.03356287  1.8059083   2.3730707 ]\n",
      " [ 1.0168487   0.72904485  1.7406166 ]\n",
      " [-1.3648106  -0.5268257  -1.0572642 ]]\n",
      "143 3.5822678 [[-0.0090815   1.8359848   2.318513  ]\n",
      " [ 1.1780181   0.881738    1.4267539 ]\n",
      " [-1.2034931  -0.37306562 -1.3723418 ]]\n",
      "144 2.7331526 [[ 0.01086614  1.752395    2.3821552 ]\n",
      " [ 1.3188697   0.41482267  1.7528176 ]\n",
      " [-1.0609149  -0.8537784  -1.0342072 ]]\n",
      "145 3.8654592 [[ 0.03257352  1.7891077   2.3237352 ]\n",
      " [ 1.4694676   0.5879913   1.429051  ]\n",
      " [-0.91128945 -0.6691523  -1.3684587 ]]\n",
      "146 2.5488353 [[-0.05296241  1.8161973   2.3821816 ]\n",
      " [ 1.0184554   0.72870874  1.7393459 ]\n",
      " [-1.3602535  -0.5291634  -1.0594836 ]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "147 3.5787086 [[-0.02846378  1.8462433   2.327637  ]\n",
      " [ 1.179664    0.88129115  1.4255549 ]\n",
      " [-1.1989076  -0.37554306 -1.37445   ]]\n",
      "148 2.7346272 [[-0.00841961  1.7624995   2.3913367 ]\n",
      " [ 1.3207908   0.4136149   1.7521044 ]\n",
      " [-1.0561097  -0.85697675 -1.0358142 ]]\n",
      "149 3.8673854 [[ 0.01335681  1.799215    2.3328447 ]\n",
      " [ 1.4715662   0.58679086  1.4281529 ]\n",
      " [-0.90630895 -0.67233545 -1.3702562 ]]\n",
      "150 2.5461953 [[-0.07194026  1.8262907   2.391066  ]\n",
      " [ 1.0209758   0.72756547  1.7379688 ]\n",
      " [-1.354857   -0.5323314  -1.0617121 ]]\n",
      "151 3.5741374 [[-0.04742802  1.8563423   2.3365023 ]\n",
      " [ 1.1822134   0.8801695   1.4241271 ]\n",
      " [-1.1934927  -0.37867278 -1.3767352 ]]\n",
      "152 2.7286217 [[-0.02735082  1.7726084   2.4001591 ]\n",
      " [ 1.3232957   0.41264975  1.7505646 ]\n",
      " [-1.05078    -0.85993505 -1.0381856 ]]\n",
      "153 3.8609898 [[-0.00554348  1.8093219   2.3416383 ]\n",
      " [ 1.4740866   0.5858209   1.4266024 ]\n",
      " [-0.9009778  -0.67529887 -1.372624  ]]\n",
      "154 2.55119 [[-0.09094796  1.8363724   2.3999922 ]\n",
      " [ 1.0220144   0.7266185   1.7378769 ]\n",
      " [-1.3509743  -0.53532326 -1.0626031 ]]\n",
      "155 3.5821524 [[-0.06641627  1.8664826   2.3453503 ]\n",
      " [ 1.1832994   0.8794397   1.4237707 ]\n",
      " [-1.1895721  -0.38136482 -1.3779638 ]]\n",
      "156 2.7238173 [[-0.04622452  1.7828809   2.4087603 ]\n",
      " [ 1.3247621   0.41278067  1.7489669 ]\n",
      " [-1.0465412  -0.8617866  -1.0405729 ]]\n",
      "157 3.8532264 [[-0.02436479  1.8195863   2.3501952 ]\n",
      " [ 1.4756671   0.5859323   1.4249102 ]\n",
      " [-0.8966284  -0.67718047 -1.3750919 ]]\n",
      "158 2.5456674 [[-0.10955675  1.8464887   2.4084847 ]\n",
      " [ 1.0238138   0.72624487  1.7364509 ]\n",
      " [-1.3463147  -0.53785455 -1.0647315 ]]\n",
      "159 3.577328 [[-0.08501135  1.8765689   2.3538592 ]\n",
      " [ 1.1851293   0.8789568   1.4224235 ]\n",
      " [-1.1848909  -0.38403112 -1.3799788 ]]\n",
      "160 2.7242484 [[-0.06475047  1.7928252   2.417342  ]\n",
      " [ 1.3267554   0.41160306  1.7481511 ]\n",
      " [-1.0417401  -0.8651033  -1.0420573 ]]\n",
      "161 3.854434 [[-0.04283562  1.8295335   2.3587189 ]\n",
      " [ 1.4777926   0.5847619   1.4239551 ]\n",
      " [-0.89169645 -0.6804817  -1.3767225 ]]\n",
      "162 2.5450082 [[-0.1278668   1.8564337   2.4168499 ]\n",
      " [ 1.02601     0.72517514  1.7353243 ]\n",
      " [-1.3413107  -0.5410823  -1.0665075 ]]\n",
      "163 3.5753174 [[-0.10330885  1.8865323   2.3621933 ]\n",
      " [ 1.1873531   0.87795615  1.4212002 ]\n",
      " [-1.179868   -0.387155   -1.3818775 ]]\n",
      "164 2.7181385 [[-0.0830108   1.8028343   2.4255934 ]\n",
      " [ 1.3289804   0.41096452  1.7465645 ]\n",
      " [-1.0367539  -0.8678553  -1.0442913 ]]\n",
      "165 3.8474944 [[-0.06106819  1.8395389   2.3669462 ]\n",
      " [ 1.480032    0.58411473  1.4223628 ]\n",
      " [-0.88670546 -0.6832448  -1.3789501 ]]\n",
      "166 2.548287 [[-0.14615951  1.8663889   2.4251876 ]\n",
      " [ 1.0270797   0.7244438   1.7349861 ]\n",
      " [-1.3374372  -0.5440008  -1.0674624 ]]\n",
      "167 3.5809844 [[-0.12158543  1.8965278   2.3704746 ]\n",
      " [ 1.188462    0.8773742   1.4206735 ]\n",
      " [-1.175963   -0.38986203 -1.3830754 ]]\n",
      "168 2.7146764 [[-0.10118934  1.8129072   2.4336991 ]\n",
      " [ 1.3304144   0.41093233  1.745163  ]\n",
      " [-1.0325758  -0.8700166  -1.0463079 ]]\n",
      "169 3.8419108 [[-0.07919818  1.8496059   2.3750093 ]\n",
      " [ 1.481577    0.58406824  1.4208645 ]\n",
      " [-0.88241637 -0.68542683 -1.3810571 ]]\n",
      "170 2.5433602 [[-0.16407531  1.8763355   2.433157  ]\n",
      " [ 1.0289437   0.7240194   1.7335467 ]\n",
      " [-1.3327509  -0.5466959  -1.0694535 ]]\n",
      "171 3.5759373 [[-0.13948993  1.9064491   2.378458  ]\n",
      " [ 1.1903507   0.8768588   1.4193003 ]\n",
      " [-1.1712595  -0.39266598 -1.3849747 ]]\n",
      "172 2.7140486 [[-0.11904324  1.8227111   2.4417493 ]\n",
      " [ 1.3323936   0.4098609   1.7442552 ]\n",
      " [-1.0278172  -0.87333274 -1.0477502 ]]\n",
      "173 3.8420913 [[-0.09700809  1.859412    2.3830135 ]\n",
      " [ 1.483652    0.5830022   1.4198554 ]\n",
      " [-0.877563   -0.68873006 -1.3826072 ]]\n",
      "174 2.54392 [[-0.18178013  1.88614     2.4410574 ]\n",
      " [ 1.0308462   0.7230533   1.73261   ]\n",
      " [-1.3280592  -0.54992235 -1.0709187 ]]\n",
      "175 3.5756156 [[-0.15718326  1.9162781   2.3863225 ]\n",
      " [ 1.1922792   0.8759843   1.418246  ]\n",
      " [-1.1665491  -0.395757   -1.386594  ]]\n",
      "176 2.7082524 [[-0.13669628  1.8326021   2.4495115 ]\n",
      " [ 1.3343616   0.4094432   1.7427049 ]\n",
      " [-1.0231025  -0.8759593  -1.0498383 ]]\n",
      "177 3.835225 [[-0.11463507  1.8692985   2.390754  ]\n",
      " [ 1.485638    0.5825738   1.4182979 ]\n",
      " [-0.8728361  -0.6913709  -1.384693  ]]\n",
      "178 2.5457299 [[-0.19942205  1.8959605   2.448879  ]\n",
      " [ 1.0319641   0.72247165  1.732074  ]\n",
      " [-1.3241374  -0.5527989  -1.0719637 ]]\n",
      "179 3.579142 [[-0.1748118   1.9261239   2.3941054 ]\n",
      " [ 1.1934292   0.8754975   1.4175829 ]\n",
      " [-1.1626016  -0.39849365 -1.3878049 ]]\n",
      "180 2.7056496 [[-0.15424308  1.8424832   2.4571774 ]\n",
      " [ 1.3357763   0.40926751  1.7414658 ]\n",
      " [-1.0189337  -0.87837625 -1.0515902 ]]\n",
      "181 3.8312054 [[-0.13213807  1.8791752   2.3983803 ]\n",
      " [ 1.487155    0.5823879   1.4169668 ]\n",
      " [-0.8685633  -0.6938013  -1.3865356 ]]\n",
      "182 2.5416865 [[-0.2167261   1.9057416   2.4564018 ]\n",
      " [ 1.0337968   0.72200364  1.7307092 ]\n",
      " [-1.3194822  -0.5556202  -1.0737978 ]]\n",
      "183 3.5745068 [[-0.19210623  1.9358864   2.401637  ]\n",
      " [ 1.1952828   0.87496376  1.416263  ]\n",
      " [-1.1579318  -0.40138912 -1.3895793 ]]\n",
      "184 2.704115 [[-0.17149882  1.852157    2.464759  ]\n",
      " [ 1.3376775   0.40834108  1.740491  ]\n",
      " [-1.0142461  -0.88162374 -1.0530304 ]]\n",
      "185 3.8303409 [[-0.14935836  1.8888502   2.4059255 ]\n",
      " [ 1.4891244   0.5814644   1.4159207 ]\n",
      " [-0.86380804 -0.6970397  -1.3880525 ]]\n",
      "186 2.54285 [[-0.23387647  1.9154093   2.4638846 ]\n",
      " [ 1.035453    0.72115326  1.7299033 ]\n",
      " [-1.3150198  -0.55881095 -1.0750695 ]]\n",
      "187 3.57511 [[-0.20924619  1.9455796   2.409084  ]\n",
      " [ 1.196963    0.8742094   1.4153371 ]\n",
      " [-1.1534516  -0.40443787 -1.391011  ]]\n",
      "188 2.698849 [[-0.18859726  1.8619144   2.4721005 ]\n",
      " [ 1.3394228   0.40805772  1.7390288 ]\n",
      " [-1.0097328  -0.88419306 -1.0549746 ]]\n",
      "189 3.823936 [[-0.16643186  1.8986028   2.4132466 ]\n",
      " [ 1.4908928   0.5811696   1.414447  ]\n",
      " [-0.85927486 -0.69962424 -1.3900014 ]]\n",
      "190 2.5435464 [[-0.25092775  1.9250883   2.4712572 ]\n",
      " [ 1.0366106   0.7206695   1.7292292 ]\n",
      " [-1.31103    -0.561671   -1.0761995 ]]\n",
      "191 3.5769007 [[-0.22628632  1.9552729   2.4164312 ]\n",
      " [ 1.1981473   0.8737809   1.4145812 ]\n",
      " [-1.1494405  -0.40721035 -1.3922497 ]]\n",
      "192 2.6967163 [[-0.20557044  1.871614    2.4793742 ]\n",
      " [ 1.3408147   0.40777695  1.7379178 ]\n",
      " [-1.0055505  -0.8868003  -1.0565498 ]]\n",
      "193 3.8209238 [[-0.18336636  1.9082993   2.4204848 ]\n",
      " [ 1.4923743   0.5808816   1.4132535 ]\n",
      " [-0.85500014 -0.70223963 -1.3916607 ]]\n",
      "194 2.54044 [[-0.2676865  1.9347091  2.4783952]\n",
      " [ 1.0383506  0.7201755  1.7279832]\n",
      " [-1.3064395 -0.5645795 -1.0778815]]\n",
      "195 3.572965 [[-0.24303667  1.9648818   2.4235728 ]\n",
      " [ 1.1999055   0.87324613  1.4133577 ]\n",
      " [-1.1448373  -0.4101593  -1.393904  ]]\n",
      "196 2.6944945 [[-0.22228952  1.8811615   2.486546  ]\n",
      " [ 1.3425977   0.40700462  1.7369071 ]\n",
      " [-1.0009482  -0.88995016 -1.058002  ]]\n",
      "197 3.8191667 [[-0.20005636  1.9178469   2.4276273 ]\n",
      " [ 1.4942061   0.58010966  1.4121937 ]\n",
      " [-0.85034937 -0.7053845  -1.3931664 ]]\n",
      "198 2.541785 [[-0.28432608  1.9442408   2.4855032 ]\n",
      " [ 1.0398073   0.71943915  1.727263  ]\n",
      " [-1.3021346  -0.5677194  -1.0790462 ]]\n",
      "199 3.5739303 [[-0.2596669   1.974437    2.4306479 ]\n",
      " [ 1.201384    0.872599    1.4125264 ]\n",
      " [-1.1405156  -0.41316587 -1.3952188 ]]\n",
      "200 2.6898274 [[-0.23887879  1.8907744   2.4935224 ]\n",
      " [ 1.3441556   0.4067942   1.7355597 ]\n",
      " [-0.9965764  -0.8925097  -1.0598142 ]]\n",
      "Prediction: [2 2 2]\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "You must feed a value for placeholder tensor 'Placeholder_5' with dtype float and shape [?,3]\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[?,3], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_5', defined at:\n  File \"D:\\Anaconda4\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Anaconda4\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\Anaconda4\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"D:\\Anaconda4\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"D:\\Anaconda4\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2705, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2809, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2869, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-f33b26e059d5>\", line 4, in <module>\n    Y = tf.placeholder(\"float\", [None, 3])\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5928, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_5' with dtype float and shape [?,3]\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[?,3], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32mD:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1277\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1278\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1279\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1262\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1263\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1349\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_5' with dtype float and shape [?,3]\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[?,3], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-963d7c6fa391>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Prediction:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprediction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mD:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    875\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    876\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 877\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    878\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    879\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1098\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1099\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1100\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1101\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1270\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1271\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1272\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1273\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1274\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mD:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1289\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1290\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1291\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1293\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: You must feed a value for placeholder tensor 'Placeholder_5' with dtype float and shape [?,3]\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[?,3], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n\nCaused by op 'Placeholder_5', defined at:\n  File \"D:\\Anaconda4\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"D:\\Anaconda4\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 497, in start\n    self.io_loop.start()\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 132, in start\n    self.asyncio_loop.run_forever()\n  File \"D:\\Anaconda4\\lib\\asyncio\\base_events.py\", line 422, in run_forever\n    self._run_once()\n  File \"D:\\Anaconda4\\lib\\asyncio\\base_events.py\", line 1432, in _run_once\n    handle._run()\n  File \"D:\\Anaconda4\\lib\\asyncio\\events.py\", line 145, in _run\n    self._callback(*self._args)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 122, in _handle_events\n    handler_func(fileobj, events)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 450, in _handle_events\n    self._handle_recv()\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 480, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 432, in _run_callback\n    callback(*args, **kwargs)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tornado\\stack_context.py\", line 300, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2705, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2809, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2869, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-40-f33b26e059d5>\", line 4, in <module>\n    Y = tf.placeholder(\"float\", [None, 3])\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\ops\\array_ops.py\", line 1735, in placeholder\n    return gen_array_ops.placeholder(dtype=dtype, shape=shape, name=name)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\ops\\gen_array_ops.py\", line 5928, in placeholder\n    \"Placeholder\", dtype=dtype, shape=shape, name=name)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\util\\deprecation.py\", line 454, in new_func\n    return func(*args, **kwargs)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3155, in create_op\n    op_def=op_def)\n  File \"D:\\DataStudy\\venv2\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1717, in __init__\n    self._traceback = tf_stack.extract_stack()\n\nInvalidArgumentError (see above for traceback): You must feed a value for placeholder tensor 'Placeholder_5' with dtype float and shape [?,3]\n\t [[Node: Placeholder_5 = Placeholder[dtype=DT_FLOAT, shape=[?,3], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"]()]]\n"
     ]
    }
   ],
   "source": [
    "# Launch graph\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    for step in range(201): \n",
    "        cost_val, W_val, _ = sess.run([cost, W, optimizer], \n",
    "                                     feed_dict = {X: x_train, Y: y_train})\n",
    "        print(step, cost_val, W_val)\n",
    "\n",
    "    print(\"Prediction:\", sess.run(prediction, feed_dict = {X: x_test}))\n",
    "    print(\"Accuracy:\", sess.run(accuracy, feed_dict = {X: x_test}))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
